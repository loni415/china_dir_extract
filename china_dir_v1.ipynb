{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f2cbf1",
   "metadata": {},
   "source": [
    "in terminal:\n",
    "conda init\n",
    "conda activate china_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60be0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ollama in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/china_dir/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U PyMuPDF\n",
    "%pip install -U ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b891c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d267b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/dev/china_directory\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c756caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- START OF CONFIGURATION ---\n",
    "# Change these values for your specific run\n",
    "PDF_PATH = \"/Users/lukasfiller/Library/CloudStorage/OneDrive-DKIAsia-PacificCenterforSecurityStudies/APCSS_Docs/topics/PLA Everything/China Directory 2024-2p5-50.pdf\"\n",
    "OUTPUT_PATH = \"output.json\"\n",
    "MODEL_NAME = \"phi4-reasoning:14b-plus-fp16\"\n",
    "OLLAMA_HOST = \"http://127.0.0.1:11434\" \n",
    "# --- END OF CONFIGURATION ---\n",
    "\n",
    "# This is the instruction set we developed, telling the LLM its role and rules.\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert data extraction system. Your sole function is to parse the provided text from a single page of a Chinese party-state leadership directory and convert its contents into a valid JSON array. Adhere strictly to the schema and parsing rules. Produce only the final JSON array as your output, without any commentary, apologies, or markdown code fences.\n",
    "\n",
    "The input text is from a two-column document. I have pre-processed it by merging lines from the left and right columns. A \"||\" separator often indicates the split between the columns.\n",
    "\n",
    "**Required Output JSON Schema:**\n",
    "[\n",
    "  {\n",
    "    \"organization_name_english\": \"string\",\n",
    "    \"organization_name_chinese\": \"string\",\n",
    "    \"document_section_title\": \"string | null\",\n",
    "    \"metadata\": {},\n",
    "    \"sub_organizations\": [],\n",
    "    \"positions\": [\n",
    "      {\n",
    "        \"title_english\": \"string\",\n",
    "        \"title_chinese\": \"string\",\n",
    "        \"metadata\": { \"count\": \"integer | null\", \"list_order_note\": \"string | null\" },\n",
    "        \"personnel\": [\n",
    "          {\n",
    "            \"name_pinyin\": \"string\",\n",
    "            \"name_chinese\": \"string\",\n",
    "            \"dob_year\": \"integer | null\",\n",
    "            \"dob_month\": \"integer | null\",\n",
    "            \"assumed_office_date\": \"YYYY-MM-DD\" | \"YYYY-MM\" | \"YYYY\" | null,\n",
    "            \"cross_reference_symbols\": [\"string\"],\n",
    "            \"gender\": \"male\" | \"female\",\n",
    "            \"ethnicity\": \"string\",\n",
    "            \"rank\": \"string | null\",\n",
    "            \"rank_chinese\": \"string | null\",\n",
    "            \"other_notes\": [\"string\"]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "**Detailed Parsing Rules:**\n",
    "- **Hierarchy:** Capture the nested structure of organizations, sub-organizations, and positions.\n",
    "- **`dob_year` / `dob_month`**: Parse from `(YY.MM)`. A `YY` < 30 is 20xx; otherwise, it's 19xx.\n",
    "- **`assumed_office_date`**: Parse from the `YY.MM.DD` format into ISO 8601 `YYYY-MM-DD`.\n",
    "- **`cross_reference_symbols`**: Collect any leading `☆`, `※`, `◎`, `○` symbols.\n",
    "- **`gender`**: If `(f)` or `(女)` is present, set to \"female\". **Default is \"male\".**\n",
    "- **`ethnicity`**: If an ethnicity like `(Mongolian)` or `(蒙古族)` is present, record it. **Default is \"Han\".**\n",
    "- **`rank` & `rank_chinese`**: Map abbreviations like `(Gen)` to `rank` and the Chinese `(上将)` to `rank_chinese`. **Default is `null` if no rank is specified.**\n",
    "- **`other_notes`**: Place any other parenthetical notes like `(executive)` or `(SPC)` here.\n",
    "- **Continuations:** If the page seems to continue a list from a previous page (e.g., starts with a list of names without a new header), structure the JSON as if it belongs to the last-mentioned organization/position. The top-level object in your response should reflect this context.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce9ef238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pdf_page(page):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF page and attempts to reconstruct the two-column layout\n",
    "    into a single, coherent text block for the LLM.\n",
    "    \"\"\"\n",
    "    blocks = page.get_text(\"blocks\")\n",
    "    blocks.sort(key=lambda b: (b[1], b[0]))\n",
    "    page_center = page.rect.width / 2\n",
    "    merged_lines = {}\n",
    "    for b in blocks:\n",
    "        y_center = (b[1] + b[3]) / 2\n",
    "        y_key = round(y_center / 10) * 10\n",
    "        text = b[4].strip().replace('\\n', ' ')\n",
    "        if not text: continue\n",
    "        if y_key not in merged_lines: merged_lines[y_key] = {'left': [], 'right': []}\n",
    "        if b[0] < page_center: merged_lines[y_key]['left'].append(text)\n",
    "        else: merged_lines[y_key]['right'].append(text)\n",
    "    processed_text = []\n",
    "    for y_key in sorted(merged_lines.keys()):\n",
    "        left_text = \" \".join(merged_lines[y_key]['left'])\n",
    "        right_text = \" \".join(merged_lines[y_key]['right'])\n",
    "        if left_text and right_text: processed_text.append(f\"{left_text} || {right_text}\")\n",
    "        elif left_text: processed_text.append(left_text)\n",
    "        elif right_text: processed_text.append(right_text)\n",
    "    return \"\\n\".join(processed_text)\n",
    "\n",
    "def get_json_from_llm(page_text, model_name, host):\n",
    "    \"\"\"\n",
    "    Sends the pre-processed page text to a specific Ollama host and gets a JSON response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a client that points to your specific Ollama server\n",
    "        client = ollama.Client(host=host)\n",
    "\n",
    "        # Use the client to make the chat request\n",
    "        response = client.chat(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "                {'role': 'user', 'content': page_text}\n",
    "            ],\n",
    "            options={'temperature': 0.0},\n",
    "            format='json'\n",
    "        )\n",
    "        content = response['message']['content']\n",
    "        return json.loads(content)\n",
    "\n",
    "    except ollama.ResponseError as e:\n",
    "        print(f\"   - An error occurred with the Ollama API: {e.error}\")\n",
    "        print(f\"   - Status code: {e.status_code}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"   - An unexpected error occurred: {e}\")\n",
    "        raw_content = \"N/A\"\n",
    "        if 'response' in locals() and response:\n",
    "            raw_content = response.get('message', {}).get('content', 'N/A')\n",
    "        print(f\"   - Raw response content: {raw_content}\")\n",
    "        return None\n",
    "    \n",
    "def stitch_json_results(all_pages_data):\n",
    "    \"\"\"\n",
    "    Merges the list of JSON objects from each page into a single,\n",
    "    hierarchically correct JSON structure.\n",
    "    \"\"\"\n",
    "    if not all_pages_data: return []\n",
    "    final_data = []\n",
    "    for page_data in all_pages_data:\n",
    "        if not page_data: continue\n",
    "        for org_data in page_data:\n",
    "            if (final_data and final_data[-1]['organization_name_english'] == org_data['organization_name_english']):\n",
    "                last_org = final_data[-1]\n",
    "                if org_data.get('positions'):\n",
    "                    if (last_org['positions'] and org_data['positions'] and last_org['positions'][-1]['title_english'] == org_data['positions'][0]['title_english']):\n",
    "                        last_org['positions'][-1]['personnel'].extend(org_data['positions'][0]['personnel'])\n",
    "                        last_org['positions'].extend(org_data['positions'][1:])\n",
    "                    else:\n",
    "                        last_org['positions'].extend(org_data['positions'])\n",
    "                if org_data.get('sub_organizations'):\n",
    "                    last_org['sub_organizations'].extend(org_data.get('sub_organizations', []))\n",
    "            else:\n",
    "                final_data.append(org_data)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fee2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing '/Users/lukasfiller/Library/CloudStorage/OneDrive-DKIAsia-PacificCenterforSecurityStudies/APCSS_Docs/topics/PLA Everything/China Directory 2024-2p5-50.pdf' with model 'phi4-reasoning:14b-plus-fp16'...\n",
      "- Processing Page 1 of 46...\n",
      "  - Successfully extracted JSON from page 1.\n",
      "- Processing Page 2 of 46...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing '{PDF_PATH}' with model '{MODEL_NAME}'...\")\n",
    "\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    print(f\"Error: PDF file not found at '{PDF_PATH}'\")\n",
    "else:\n",
    "    doc = fitz.open(PDF_PATH)\n",
    "    num_pages = len(doc)\n",
    "    all_pages_data = []\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        print(f\"- Processing Page {i + 1} of {num_pages}...\")\n",
    "        page_text = preprocess_pdf_page(page)\n",
    "        \n",
    "        if not page_text.strip():\n",
    "            print(\"  - Page is empty, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        page_json = get_json_from_llm(page_text, MODEL_NAME, OLLAMA_HOST)\n",
    "        \n",
    "        if page_json:\n",
    "            print(f\"  - Successfully extracted JSON from page {i+1}.\")\n",
    "            all_pages_data.append(page_json)\n",
    "        else:\n",
    "            print(f\"  - Failed to extract JSON from page {i+1}. It might be empty or have caused an error.\")\n",
    "\n",
    "    print(\"\\nStitching JSON data from all pages...\")\n",
    "    final_stitched_data = stitch_json_results(all_pages_data)\n",
    "\n",
    "    print(f\"Writing final structured data to '{OUTPUT_PATH}'...\")\n",
    "    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_stitched_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "china_dir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
